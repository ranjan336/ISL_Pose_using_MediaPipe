{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load your data (replace with your file path)\n",
    "#data= pd.read_parquet('your_landmark_data.parquet')\n",
    "\n",
    "df_from_parquet = pd.read_parquet(r\"C:\\Users\\ranjan.patra\\OneDrive - Lingaro Sp. z o. o\\DATA\\IITJ\\Course\\Projects\\ISL\\ISL_CSLRT_Corpus\\Mp_Data\\LandMarks_lh_rh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_from_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = df_from_parquet['Label'].unique()\n",
    "label_id_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "# Step 3: Map the Label to Label_id in the DataFrame\n",
    "df_from_parquet['Label_id'] = df_from_parquet['Label'].map(label_id_mapping)\n",
    "label_info = [{label, label_id} for label, label_id in label_id_mapping.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set = {tuple(s) for s in df_from_parquet['Keypoints']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=df_from_parquet[['Label_id','Sample_Number','Frame_Number','Keypoints']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=df_from_parquet[['Label','Sample_Number','Frame_Number','Keypoints']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Map the Label to Label_id in the DataFrame\n",
    "df_from_parquet['Label_id'] = df_from_parquet['Label'].map(label_id_mapping)\n",
    "label_info = [{label, label_id} for label, label_id in label_id_mapping.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Ensure Keypoints are converted to lists if they are not already\n",
    "df_from_parquet['Keypoints'] = df_from_parquet['Keypoints'].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)\n",
    "\n",
    "# Step 2: Group by the necessary columns and aggregate\n",
    "grouped = df_from_parquet.groupby(['Label','Label_id', 'sample_type', 'Sample_Number']).apply(\n",
    "    lambda x: x[['Frame_Number', 'Keypoints']].to_dict('records')\n",
    ").reset_index(name='frames_keypoints')\n",
    "\n",
    "# Step 3: Convert the grouped result to a JSON-like structure\n",
    "grouped_json = grouped.to_dict(orient='records')\n",
    "\n",
    "# Step 5: Convert the result to a JSON string\n",
    "json_output = json.dumps(grouped_json, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Ensure grouped_json is treated as an array\n",
    "json_output_array = [grouped_json]  # or simply treat it as is\n",
    "json_output = json.dumps(json_output_array, indent=4)\n",
    "\n",
    "# If grouped_json is already a list, you can omit wrapping it:\n",
    "json_output = json.dumps(grouped_json, indent=4)\n",
    "\n",
    "# Printing or using the json output\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step to remove names and keep only numbers in the grouped_json structure\n",
    "def remove_names_and_keep_numbers(entry):\n",
    "    return {\n",
    "        'Label_id': entry['Label_id'],\n",
    "        'Sample_Number': entry['Sample_Number'],\n",
    "        'frames_keypoints': [\n",
    "            {'Frame_Number': frame['Frame_Number'], 'Keypoints': frame['Keypoints']}\n",
    "            for frame in entry['frames_keypoints']\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Applying this function to the grouped_json\n",
    "numeric_grouped_json = [remove_names_and_keep_numbers(item) for item in grouped_json]\n",
    "\n",
    "# Convert to JSON string\n",
    "json_output = json.dumps(numeric_grouped_json, indent=4)\n",
    "\n",
    "# Printing or using the output\n",
    "print(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grouped_json[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(json_output)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(array_output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read from a parquet file\n",
    "\n",
    "# Proceed with mapping and processing as before\n",
    "unique_labels = df_from_parquet['Label'].unique()\n",
    "label_id_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "df_from_parquet['Label_id'] = df_from_parquet['Label'].map(label_id_mapping)\n",
    "df_from_parquet['Keypoints'] = df_from_parquet['Keypoints'].apply(lambda x: x.tolist() if isinstance(x, np.ndarray) else x)\n",
    "\n",
    "# Ensure this is a DataFrame before passing it\n",
    "if isinstance(df_from_parquet, pd.DataFrame):\n",
    "    grouped = df_from_parquet.groupby(['Label', 'Label_id', 'sample_type', 'Sample_Number']).apply(\n",
    "        lambda x: x[['Frame_Number', 'Keypoints']].to_dict('records')\n",
    "    ).reset_index(name='frames_keypoints')\n",
    "    \n",
    "    grouped_json = grouped.to_dict(orient='records')\n",
    "    json_output = json.dumps(grouped_json, indent=4)\n",
    "\n",
    "    # Optionally save to a file\n",
    "    with open('output.json', 'w') as json_file:\n",
    "        json_file.write(json_output)\n",
    "else:\n",
    "    print(\"Data is not a DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(json_output)\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def extract_keypoints(df):\n",
    "    keypoints = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        keypoint_str = row[1]['frames_keypoints'][0]['Keypoints']\n",
    "        \n",
    "        if isinstance(keypoint_str, str):\n",
    "            print(\"Is Str\")\n",
    "            # Remove curly braces and split the string by commas\n",
    "            keypoint_str = keypoint_str.replace('{', '').replace('}', '')\n",
    "            try:\n",
    "                print(\"Is not Str\")\n",
    "                # Convert the string into a list of floats\n",
    "                keypoint_list = [float(val) for val in keypoint_str.split(',')]\n",
    "                keypoint_str = keypoint_list.replace('{', '').replace('}', '')\n",
    "            except ValueError as e:\n",
    "                print(f\"Error converting keypoints: {keypoint_str} -> {e}\")\n",
    "                continue  # Skip problematic rows if conversion fails\n",
    "        else:\n",
    "            keypoint_list = keypoint_str  # If not a string, assume it's already correct\n",
    "        \n",
    "        keypoints.append(keypoint_list)\n",
    "        labels.append(row['Label'])  # Assuming label is numeric\n",
    "    \n",
    "    return np.array(keypoints), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]\n",
    "#['frames_keypoints'][0]['Keypoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = extract_keypoints(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check keypoints data and ensure it's numeric\n",
    "print(\"Keypoints shape: \", X.shape)\n",
    "print(\"Sample keypoints data: \", X[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)  # Convert keypoints to float32\n",
    "X = X / np.max(X)  # Normalize between 0 and 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
